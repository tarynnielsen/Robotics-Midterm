{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Classic cart-pole system implemented by Rich Sutton et al.\n",
    "Copied from http://incompleteideas.net/sutton/book/code/pole.c\n",
    "permalink: https://perma.cc/C9ZM-652R\n",
    "\"\"\"\n",
    "import math\n",
    "from typing import Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "from gym import logger, spaces\n",
    "from gym.envs.classic_control import utils\n",
    "from gym.error import DependencyNotInstalled\n",
    "\n",
    "\n",
    "class CartPoleEnv(gym.Env[np.ndarray, Union[int, np.ndarray]]):\n",
    "    \"\"\"\n",
    "    ### Description\n",
    "\n",
    "    This environment corresponds to the version of the cart-pole problem described by Barto, Sutton, and Anderson in\n",
    "    [\"Neuronlike Adaptive Elements That Can Solve Difficult Learning Control Problem\"](https://ieeexplore.ieee.org/document/6313077).\n",
    "    A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track.\n",
    "    The pendulum is placed upright on the cart and the goal is to balance the pole by applying forces\n",
    "     in the left and right direction on the cart.\n",
    "\n",
    "    ### Action Space\n",
    "\n",
    "    The action is a `ndarray` with shape `(1,)` which can take values `{0, 1}` indicating the direction\n",
    "     of the fixed force the cart is pushed with.\n",
    "\n",
    "    | Num | Action                 |\n",
    "    |-----|------------------------|\n",
    "    | 0   | Push cart to the left  |\n",
    "    | 1   | Push cart to the right |\n",
    "\n",
    "    **Note**: The velocity that is reduced or increased by the applied force is not fixed and it depends on the angle\n",
    "     the pole is pointing. The center of gravity of the pole varies the amount of energy needed to move the cart underneath it\n",
    "\n",
    "    ### Observation Space\n",
    "\n",
    "    The observation is a `ndarray` with shape `(4,)` with the values corresponding to the following positions and velocities:\n",
    "\n",
    "    | Num | Observation           | Min                 | Max               |\n",
    "    |-----|-----------------------|---------------------|-------------------|\n",
    "    | 0   | Cart Position         | -4.8                | 4.8               |\n",
    "    | 1   | Cart Velocity         | -Inf                | Inf               |\n",
    "    | 2   | Pole Angle            | ~ -0.418 rad (-24°) | ~ 0.418 rad (24°) |\n",
    "    | 3   | Pole Angular Velocity | -Inf                | Inf               |\n",
    "\n",
    "    **Note:** While the ranges above denote the possible values for observation space of each element,\n",
    "        it is not reflective of the allowed values of the state space in an unterminated episode. Particularly:\n",
    "    -  The cart x-position (index 0) can be take values between `(-4.8, 4.8)`, but the episode terminates\n",
    "       if the cart leaves the `(-2.4, 2.4)` range.\n",
    "    -  The pole angle can be observed between  `(-.418, .418)` radians (or **±24°**), but the episode terminates\n",
    "       if the pole angle is not in the range `(-.2095, .2095)` (or **±12°**)\n",
    "\n",
    "    ### Rewards\n",
    "\n",
    "    Since the goal is to keep the pole upright for as long as possible, a reward of `+1` for every step taken,\n",
    "    including the termination step, is allotted. The threshold for rewards is 475 for v1.\n",
    "\n",
    "    ### Starting State\n",
    "\n",
    "    All observations are assigned a uniformly random value in `(-0.05, 0.05)`\n",
    "\n",
    "    ### Episode End\n",
    "\n",
    "    The episode ends if any one of the following occurs:\n",
    "\n",
    "    1. Termination: Pole Angle is greater than ±12°\n",
    "    2. Termination: Cart Position is greater than ±2.4 (center of the cart reaches the edge of the display)\n",
    "    3. Truncation: Episode length is greater than 500 (200 for v0)\n",
    "\n",
    "    ### Arguments\n",
    "\n",
    "    ```\n",
    "    gym.make('CartPole-v1')\n",
    "    ```\n",
    "\n",
    "    No additional arguments are currently supported.\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\n",
    "        \"render_modes\": [\"human\", \"rgb_array\"],\n",
    "        \"render_fps\": 50,\n",
    "    }\n",
    "\n",
    "    def __init__(self, render_mode: Optional[str] = None):\n",
    "        self.gravity = 9.8\n",
    "        self.masscart = 1.0\n",
    "        self.masspole = 0.1\n",
    "        self.total_mass = self.masspole + self.masscart\n",
    "        self.length = 0.5  # actually half the pole's length\n",
    "        self.polemass_length = self.masspole * self.length\n",
    "        self.force_mag = 10.0\n",
    "        self.tau = 0.02  # seconds between state updates\n",
    "        self.kinematics_integrator = \"euler\"\n",
    "\n",
    "        # Angle at which to fail the episode\n",
    "        self.theta_threshold_radians = 12 * 2 * math.pi / 360\n",
    "        self.x_threshold = 2.4\n",
    "\n",
    "        # Angle limit set to 2 * theta_threshold_radians so failing observation\n",
    "        # is still within bounds.\n",
    "        high = np.array(\n",
    "            [\n",
    "                self.x_threshold * 2,\n",
    "                np.finfo(np.float32).max,\n",
    "                self.theta_threshold_radians * 2,\n",
    "                np.finfo(np.float32).max,\n",
    "            ],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        self.observation_space = spaces.Box(-high, high, dtype=np.float32)\n",
    "\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        self.screen_width = 600\n",
    "        self.screen_height = 400\n",
    "        self.screen = None\n",
    "        self.clock = None\n",
    "        self.isopen = True\n",
    "        self.state = None\n",
    "\n",
    "        self.steps_beyond_terminated = None\n",
    "\n",
    "    def step(self, action):\n",
    "        err_msg = f\"{action!r} ({type(action)}) invalid\"\n",
    "        assert self.action_space.contains(action), err_msg\n",
    "        assert self.state is not None, \"Call reset before using step method.\"\n",
    "        x, x_dot, theta, theta_dot = self.state\n",
    "        force = self.force_mag if action == 1 else -self.force_mag\n",
    "        costheta = math.cos(theta)\n",
    "        sintheta = math.sin(theta)\n",
    "\n",
    "        # For the interested reader:\n",
    "        # https://coneural.org/florian/papers/05_cart_pole.pdf\n",
    "        temp = (\n",
    "            force + self.polemass_length * theta_dot**2 * sintheta\n",
    "        ) / self.total_mass\n",
    "        thetaacc = (self.gravity * sintheta - costheta * temp) / (\n",
    "            self.length * (4.0 / 3.0 - self.masspole * costheta**2 / self.total_mass)\n",
    "        )\n",
    "        xacc = temp - self.polemass_length * thetaacc * costheta / self.total_mass\n",
    "\n",
    "        if self.kinematics_integrator == \"euler\":\n",
    "            x = x + self.tau * x_dot\n",
    "            x_dot = x_dot + self.tau * xacc\n",
    "            theta = theta + self.tau * theta_dot\n",
    "            theta_dot = theta_dot + self.tau * thetaacc\n",
    "        else:  # semi-implicit euler\n",
    "            x_dot = x_dot + self.tau * xacc\n",
    "            x = x + self.tau * x_dot\n",
    "            theta_dot = theta_dot + self.tau * thetaacc\n",
    "            theta = theta + self.tau * theta_dot\n",
    "\n",
    "        self.state = (x, x_dot, theta, theta_dot)\n",
    "\n",
    "        terminated = bool(\n",
    "            x < -self.x_threshold\n",
    "            or x > self.x_threshold\n",
    "            or theta < -self.theta_threshold_radians\n",
    "            or theta > self.theta_threshold_radians\n",
    "        )\n",
    "\n",
    "        if not terminated:\n",
    "            reward = 1.0\n",
    "        elif self.steps_beyond_terminated is None:\n",
    "            # Pole just fell!\n",
    "            self.steps_beyond_terminated = 0\n",
    "            reward = 1.0\n",
    "        else:\n",
    "            if self.steps_beyond_terminated == 0:\n",
    "                logger.warn(\n",
    "                    \"You are calling 'step()' even though this \"\n",
    "                    \"environment has already returned terminated = True. You \"\n",
    "                    \"should always call 'reset()' once you receive 'terminated = \"\n",
    "                    \"True' -- any further steps are undefined behavior.\"\n",
    "                )\n",
    "            self.steps_beyond_terminated += 1\n",
    "            reward = 0.0\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "        return np.array(self.state, dtype=np.float32), reward, terminated, False, {}\n",
    "\n",
    "    def reset(\n",
    "        self,\n",
    "        *,\n",
    "        seed: Optional[int] = None,\n",
    "        options: Optional[dict] = None,\n",
    "    ):\n",
    "        super().reset(seed=seed)\n",
    "        # Note that if you use custom reset bounds, it may lead to out-of-bound\n",
    "        # state/observations.\n",
    "        low, high = utils.maybe_parse_reset_bounds(\n",
    "            options, -0.05, 0.05  # default low\n",
    "        )  # default high\n",
    "        self.state = self.np_random.uniform(low=low, high=high, size=(4,))\n",
    "        self.steps_beyond_terminated = None\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "        return np.array(self.state, dtype=np.float32), {}\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode is None:\n",
    "            gym.logger.warn(\n",
    "                \"You are calling render method without specifying any render mode. \"\n",
    "                \"You can specify the render_mode at initialization, \"\n",
    "                f'e.g. gym(\"{self.spec.id}\", render_mode=\"rgb_array\")'\n",
    "            )\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            import pygame\n",
    "            from pygame import gfxdraw\n",
    "        except ImportError:\n",
    "            raise DependencyNotInstalled(\n",
    "                \"pygame is not installed, run `pip install gym[classic_control]`\"\n",
    "            )\n",
    "\n",
    "        if self.screen is None:\n",
    "            pygame.init()\n",
    "            if self.render_mode == \"human\":\n",
    "                pygame.display.init()\n",
    "                self.screen = pygame.display.set_mode(\n",
    "                    (self.screen_width, self.screen_height)\n",
    "                )\n",
    "            else:  # mode == \"rgb_array\"\n",
    "                self.screen = pygame.Surface((self.screen_width, self.screen_height))\n",
    "        if self.clock is None:\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        world_width = self.x_threshold * 2\n",
    "        scale = self.screen_width / world_width\n",
    "        polewidth = 10.0\n",
    "        polelen = scale * (2 * self.length)\n",
    "        cartwidth = 50.0\n",
    "        cartheight = 30.0\n",
    "\n",
    "        if self.state is None:\n",
    "            return None\n",
    "\n",
    "        x = self.state\n",
    "\n",
    "        self.surf = pygame.Surface((self.screen_width, self.screen_height))\n",
    "        self.surf.fill((255, 255, 255))\n",
    "\n",
    "        l, r, t, b = -cartwidth / 2, cartwidth / 2, cartheight / 2, -cartheight / 2\n",
    "        axleoffset = cartheight / 4.0\n",
    "        cartx = x[0] * scale + self.screen_width / 2.0  # MIDDLE OF CART\n",
    "        carty = 100  # TOP OF CART\n",
    "        cart_coords = [(l, b), (l, t), (r, t), (r, b)]\n",
    "        cart_coords = [(c[0] + cartx, c[1] + carty) for c in cart_coords]\n",
    "        gfxdraw.aapolygon(self.surf, cart_coords, (0, 0, 0))\n",
    "        gfxdraw.filled_polygon(self.surf, cart_coords, (0, 0, 0))\n",
    "\n",
    "        l, r, t, b = (\n",
    "            -polewidth / 2,\n",
    "            polewidth / 2,\n",
    "            polelen - polewidth / 2,\n",
    "            -polewidth / 2,\n",
    "        )\n",
    "\n",
    "        pole_coords = []\n",
    "        for coord in [(l, b), (l, t), (r, t), (r, b)]:\n",
    "            coord = pygame.math.Vector2(coord).rotate_rad(-x[2])\n",
    "            coord = (coord[0] + cartx, coord[1] + carty + axleoffset)\n",
    "            pole_coords.append(coord)\n",
    "        gfxdraw.aapolygon(self.surf, pole_coords, (202, 152, 101))\n",
    "        gfxdraw.filled_polygon(self.surf, pole_coords, (202, 152, 101))\n",
    "\n",
    "        gfxdraw.aacircle(\n",
    "            self.surf,\n",
    "            int(cartx),\n",
    "            int(carty + axleoffset),\n",
    "            int(polewidth / 2),\n",
    "            (129, 132, 203),\n",
    "        )\n",
    "        gfxdraw.filled_circle(\n",
    "            self.surf,\n",
    "            int(cartx),\n",
    "            int(carty + axleoffset),\n",
    "            int(polewidth / 2),\n",
    "            (129, 132, 203),\n",
    "        )\n",
    "\n",
    "        gfxdraw.hline(self.surf, 0, self.screen_width, carty, (0, 0, 0))\n",
    "\n",
    "        self.surf = pygame.transform.flip(self.surf, False, True)\n",
    "        self.screen.blit(self.surf, (0, 0))\n",
    "        if self.render_mode == \"human\":\n",
    "            pygame.event.pump()\n",
    "            self.clock.tick(self.metadata[\"render_fps\"])\n",
    "            pygame.display.flip()\n",
    "\n",
    "        elif self.render_mode == \"rgb_array\":\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(self.screen)), axes=(1, 0, 2)\n",
    "            )\n",
    "\n",
    "    def close(self):\n",
    "        if self.screen is not None:\n",
    "            import pygame\n",
    "\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "            self.isopen = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.policies.boltzmann_policy import BoltzmannPolicy\n",
    "from tf_agents.policies import TFPolicy, random_tf_policy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.utils import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n"
     ]
    }
   ],
   "source": [
    "# Basic setup for the nn\n",
    "train_gym_env = suite_gym.load('CartPole-v1')\n",
    "test_gym_env = suite_gym.load('CartPole-v1')\n",
    "\n",
    "print(train_gym_env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert envs to tensors for tf\n",
    "train_env = tf_py_environment.TFPyEnvironment(train_gym_env)\n",
    "test_env = tf_py_environment.TFPyEnvironment(test_gym_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_tensor_spec = tensor_spec.from_spec(train_env.action_spec())\n",
    "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
    "\n",
    "# dense net\n",
    "layers = [Dense(16, activation=\"relu\"), Dense(32, activation=\"relu\"), Dense(64, activation=\"relu\")]\n",
    "\n",
    "# output layer\n",
    "output = Dense(num_actions, activation=\"sigmoid\")\n",
    "\n",
    "model = sequential.Sequential(layers + [output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=model,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m random_policy \u001b[38;5;241m=\u001b[39m random_tf_policy\u001b[38;5;241m.\u001b[39mRandomTFPolicy(train_env\u001b[38;5;241m.\u001b[39mtime_step_spec(),\n\u001b[0;32m      2\u001b[0m                                                 train_env\u001b[38;5;241m.\u001b[39maction_spec())\n\u001b[0;32m      3\u001b[0m example_environment \u001b[38;5;241m=\u001b[39m tf_py_environment\u001b[38;5;241m.\u001b[39mTFPyEnvironment(\n\u001b[0;32m      4\u001b[0m     suite_gym\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCartPole-v1\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m----> 5\u001b[0m time_step \u001b[38;5;241m=\u001b[39m \u001b[43mexample_environment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m policy\u001b[38;5;241m.\u001b[39maction(time_step)\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tf_agents\\environments\\tf_environment.py:209\u001b[0m, in \u001b[0;36mTFEnvironment.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Resets the environment and returns the current time_step.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m        corresponding to `observation_spec()`.\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tf_agents\\environments\\tf_py_environment.py:269\u001b[0m, in \u001b[0;36mTFPyEnvironment._reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute(_reset_py)\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreset\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 269\u001b[0m   reset_op \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_isolated_reset_py\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreset_py_func\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# No inputs.\u001b[39;49;00m\n\u001b[0;32m    271\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies([reset_op]):\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_time_step()\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tf_agents\\environments\\tf_py_environment.py:266\u001b[0m, in \u001b[0;36mTFPyEnvironment._reset.<locals>._isolated_reset_py\u001b[1;34m()\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_isolated_reset_py\u001b[39m():\n\u001b[1;32m--> 266\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_reset_py\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tf_agents\\environments\\tf_py_environment.py:214\u001b[0m, in \u001b[0;36mTFPyEnvironment._execute\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    213\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool:\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    215\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mapply(fn, args\u001b[38;5;241m=\u001b[39margs, kwds\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tf_agents\\environments\\tf_py_environment.py:263\u001b[0m, in \u001b[0;36mTFPyEnvironment._reset.<locals>._reset_py\u001b[1;34m()\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_reset_py\u001b[39m():\n\u001b[0;32m    262\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m _check_not_called_concurrently(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock):\n\u001b[1;32m--> 263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tf_agents\\environments\\py_environment.py:198\u001b[0m, in \u001b[0;36mPyEnvironment.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ts\u001b[38;5;241m.\u001b[39mTimeStep:\n\u001b[0;32m    184\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Starts a new sequence and returns the first `TimeStep` of this sequence.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m  Note: Subclasses cannot override this directly. Subclasses implement\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m        corresponding to `observation_spec()`.\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 198\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tf_agents\\environments\\batched_py_environment.py:150\u001b[0m, in \u001b[0;36mBatchedPyEnvironment._reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reset all environments and combine the resulting observation.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03m  Time step with batch dimension.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_envs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m nest_utils\u001b[38;5;241m.\u001b[39mbatch_nested_array(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_envs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m   time_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute(\u001b[38;5;28;01mlambda\u001b[39;00m env: env\u001b[38;5;241m.\u001b[39mreset(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_envs)\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tf_agents\\environments\\py_environment.py:198\u001b[0m, in \u001b[0;36mPyEnvironment.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ts\u001b[38;5;241m.\u001b[39mTimeStep:\n\u001b[0;32m    184\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Starts a new sequence and returns the first `TimeStep` of this sequence.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m  Note: Subclasses cannot override this directly. Subclasses implement\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m        corresponding to `observation_spec()`.\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 198\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tf_agents\\environments\\wrappers.py:109\u001b[0m, in \u001b[0;36mTimeLimit._reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_reset\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    108\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 109\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tf_agents\\environments\\py_environment.py:198\u001b[0m, in \u001b[0;36mPyEnvironment.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ts\u001b[38;5;241m.\u001b[39mTimeStep:\n\u001b[0;32m    184\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Starts a new sequence and returns the first `TimeStep` of this sequence.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m  Note: Subclasses cannot override this directly. Subclasses implement\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m        corresponding to `observation_spec()`.\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 198\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tf_agents\\environments\\gym_wrapper.py:216\u001b[0m, in \u001b[0;36mGymWrapper._reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_obs_space_dtype:\n\u001b[1;32m--> 216\u001b[0m   observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_obs_space_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ts\u001b[38;5;241m.\u001b[39mrestart(observation)\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tf_agents\\environments\\gym_wrapper.py:263\u001b[0m, in \u001b[0;36mGymWrapper._to_obs_space_dtype\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m    261\u001b[0m matched_observations \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m spec, obs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_obs_spec, flat_obs):\n\u001b[1;32m--> 263\u001b[0m   matched_observations\u001b[38;5;241m.\u001b[39mappend(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_observation_spec, matched_observations\n\u001b[0;32m    266\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())\n",
    "example_environment = tf_py_environment.TFPyEnvironment(\n",
    "    suite_gym.load('CartPole-v1'))\n",
    "time_step = example_environment.reset()\n",
    "policy.action(time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m avg_return\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     18\u001b[0m policy \u001b[38;5;241m=\u001b[39m BoltzmannPolicy(policy\u001b[38;5;241m=\u001b[39magent\u001b[38;5;241m.\u001b[39mpolicy)\n\u001b[1;32m---> 19\u001b[0m \u001b[43mcompute_avg_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample_environment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 6\u001b[0m, in \u001b[0;36mcompute_avg_return\u001b[1;34m(environment, policy, num_episodes)\u001b[0m\n\u001b[0;32m      3\u001b[0m total_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_episodes):\n\u001b[1;32m----> 6\u001b[0m \ttime_step \u001b[38;5;241m=\u001b[39m \u001b[43menvironment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \tepisode_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m      9\u001b[0m \t\u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m time_step\u001b[38;5;241m.\u001b[39mis_last():\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tf_agents\\environments\\tf_environment.py:209\u001b[0m, in \u001b[0;36mTFEnvironment.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Resets the environment and returns the current time_step.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m        corresponding to `observation_spec()`.\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tf_agents\\environments\\tf_py_environment.py:269\u001b[0m, in \u001b[0;36mTFPyEnvironment._reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute(_reset_py)\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreset\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 269\u001b[0m   reset_op \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_isolated_reset_py\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreset_py_func\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# No inputs.\u001b[39;49;00m\n\u001b[0;32m    271\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies([reset_op]):\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_time_step()\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tf_agents\\environments\\tf_py_environment.py:266\u001b[0m, in \u001b[0;36mTFPyEnvironment._reset.<locals>._isolated_reset_py\u001b[1;34m()\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_isolated_reset_py\u001b[39m():\n\u001b[1;32m--> 266\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_reset_py\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tf_agents\\environments\\tf_py_environment.py:214\u001b[0m, in \u001b[0;36mTFPyEnvironment._execute\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    213\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool:\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    215\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mapply(fn, args\u001b[38;5;241m=\u001b[39margs, kwds\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tf_agents\\environments\\tf_py_environment.py:263\u001b[0m, in \u001b[0;36mTFPyEnvironment._reset.<locals>._reset_py\u001b[1;34m()\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_reset_py\u001b[39m():\n\u001b[0;32m    262\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m _check_not_called_concurrently(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock):\n\u001b[1;32m--> 263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tf_agents\\environments\\py_environment.py:198\u001b[0m, in \u001b[0;36mPyEnvironment.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ts\u001b[38;5;241m.\u001b[39mTimeStep:\n\u001b[0;32m    184\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Starts a new sequence and returns the first `TimeStep` of this sequence.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m  Note: Subclasses cannot override this directly. Subclasses implement\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m        corresponding to `observation_spec()`.\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 198\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tf_agents\\environments\\batched_py_environment.py:150\u001b[0m, in \u001b[0;36mBatchedPyEnvironment._reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reset all environments and combine the resulting observation.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03m  Time step with batch dimension.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_envs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m nest_utils\u001b[38;5;241m.\u001b[39mbatch_nested_array(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_envs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m   time_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute(\u001b[38;5;28;01mlambda\u001b[39;00m env: env\u001b[38;5;241m.\u001b[39mreset(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_envs)\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tf_agents\\environments\\py_environment.py:198\u001b[0m, in \u001b[0;36mPyEnvironment.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ts\u001b[38;5;241m.\u001b[39mTimeStep:\n\u001b[0;32m    184\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Starts a new sequence and returns the first `TimeStep` of this sequence.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m  Note: Subclasses cannot override this directly. Subclasses implement\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m        corresponding to `observation_spec()`.\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 198\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tf_agents\\environments\\wrappers.py:109\u001b[0m, in \u001b[0;36mTimeLimit._reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_reset\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    108\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 109\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tf_agents\\environments\\py_environment.py:198\u001b[0m, in \u001b[0;36mPyEnvironment.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ts\u001b[38;5;241m.\u001b[39mTimeStep:\n\u001b[0;32m    184\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Starts a new sequence and returns the first `TimeStep` of this sequence.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m  Note: Subclasses cannot override this directly. Subclasses implement\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m        corresponding to `observation_spec()`.\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 198\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tf_agents\\environments\\gym_wrapper.py:216\u001b[0m, in \u001b[0;36mGymWrapper._reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_obs_space_dtype:\n\u001b[1;32m--> 216\u001b[0m   observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_obs_space_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ts\u001b[38;5;241m.\u001b[39mrestart(observation)\n",
      "File \u001b[1;32m~\\school\\cs5510\\Robotics-Midterm\\Problem1\\venv\\lib\\site-packages\\tf_agents\\environments\\gym_wrapper.py:263\u001b[0m, in \u001b[0;36mGymWrapper._to_obs_space_dtype\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m    261\u001b[0m matched_observations \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m spec, obs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_obs_spec, flat_obs):\n\u001b[1;32m--> 263\u001b[0m   matched_observations\u001b[38;5;241m.\u001b[39mappend(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_observation_spec, matched_observations\n\u001b[0;32m    266\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "\ttotal_return = 0.0\n",
    "\tfor _ in range(num_episodes):\n",
    "\n",
    "\t\ttime_step = environment.reset()\n",
    "\t\tepisode_return = 0.0\n",
    "\n",
    "\t\twhile not time_step.is_last():\n",
    "\t\t\taction_step = policy.action(time_step)\n",
    "\t\t\ttime_step = environment.step(action_step.action)\n",
    "\t\t\tepisode_return += time_step.reward\n",
    "\t\ttotal_return += episode_return\n",
    "\n",
    "\tavg_return = total_return / num_episodes\n",
    "\treturn avg_return.numpy()[0]\n",
    "\n",
    "policy = BoltzmannPolicy(policy=agent.policy)\n",
    "compute_avg_return(example_environment, random_policy, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <video width=\"640\" height=\"480\" controls>\n",
       "    <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
       "  Your browser does not support the video tag.\n",
       "  </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import IPython\n",
    "import imageio\n",
    "\n",
    "\n",
    "def embed_mp4(filename):\n",
    "  \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
    "  video = open(filename,'rb').read()\n",
    "  b64 = base64.b64encode(video)\n",
    "  tag = '''\n",
    "  <video width=\"640\" height=\"480\" controls>\n",
    "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "  </video>'''.format(b64.decode())\n",
    "\n",
    "  return IPython.display.HTML(tag)\n",
    "\n",
    "def create_policy_eval_video(policy, filename, num_episodes=5, fps=30):\n",
    "  filename = filename + \".mp4\"\n",
    "  with imageio.get_writer(filename, fps=fps) as video:\n",
    "    for _ in range(num_episodes):\n",
    "      time_step = test_env.reset()\n",
    "      video.append_data(test_gym_env.render())\n",
    "      while not time_step.is_last():\n",
    "        action_step = policy.action(time_step)\n",
    "        time_step = test_env.step(action_step.action)\n",
    "        video.append_data(test_gym_env.render())\n",
    "  return embed_mp4(filename)\n",
    "\n",
    "create_policy_eval_video(agent.policy, \"untrained-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
